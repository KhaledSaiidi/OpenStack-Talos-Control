# ðŸš€ StackTalosOpsEngine: Production-Grade Cloud Automation

This repository delivers a production-grade automation engine designed for deploying and managing a fully declarative cloud platform. Utilizing Infrastructure as Code (IaC) and a multi-layered GitOps workflow, the system establishes a robust, self-managing environment where OpenStack serves as the virtualized substrate, and a Talos-based cluster handles continuous operations.

The design targets repeatable production bring-up and lifecycle management, achieving a closed-loop system that spans from the virtualization host up to application delivery.

## âš™ï¸ Multi-Layer Architecture

This system is built upon two distinct, yet interconnected, declarative layers:
### 1. Infrastructure Layer (The Substrate)
This layer establishes the core virtualization and foundational cloud components:
* **Provisioning (Terraform/Libvirt):** Provisions all VMs (OpenStack controllers, computes, storage) and the initial **Talos Kubernetes nodes**.
* **Deployment (Ansible/OSA):** Deploys the full **OpenStack** cloud on its dedicated VMs and bootstraps the **Talos Management Cluster** on the Kubernetes nodes.
### 2. Management Layer (The Ops Engine)
The Talos Cluster acts as the single, declarative management plane for all tenant resources:
* **Orchestration (FluxCD/CAPI):** The cluster hosts FluxCD and Cluster API.
* **Control Flow:** CAPI continuously monitors Git and uses the OpenStack APIs to provision, manage, and reconcile all tenant workloads (VMs, networking, storage) on demand.
This workflow enforces a **GitOps-driven lifecycle model** where every component, from the base VMs to the deployed applications, is consistently controlled and managed from Git.

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bare-metal   â”‚  scripts/init.sh installs libvirt/qemu/terraform/ansible
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Terraform + Ansible
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ terraform/openstack-libvirt                        â”‚
â”‚  - storage pool + NAT network                      â”‚
â”‚  - controller/compute/storage VMs                  â”‚
â”‚  - cloud-init + Ansible inventory                  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ kicks off ansible/roles/openstack/site.yaml
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenStack-Ansible deployment (controller[0])       â”‚
â”‚  - OSA stable/epoxy                                â”‚
â”‚  - OVN networking, LVM Cinder backend              â”‚
â”‚  - Full OpenStack control plane                    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ terraform/talos-cluster-bootstrap                  â”‚
â”‚  - Talos control-plane + worker VMs                â”‚
â”‚  - ansible/roles/k8s-talos bootstraps the cluster  â”‚
â”‚  - Flux + Cluster API installed on Talos           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Flux reconciles Cluster API manifests
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenStack (Nova/Cinder/Neutron)                    â”‚
â”‚  - CAPI uses OpenStack APIs to create tenant VMs   â”‚
â”‚  - GitOps drives application delivery              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Repository Layout

```
scripts/
  â”œâ”€ init.sh                   # Host prerequisite installer
  â”œâ”€ bootstrap-openstack.sh    # Terraform/Ansible wrapper for OpenStack stack
  â””â”€ bootstrap-talos.sh        # Terraform/Ansible wrapper for Talos stack
terraform/
  â”œâ”€ openstack-libvirt/        # Libvirt module for OpenStack VMs
  â””â”€ talos-cluster-bootstrap/  # Talos VM module
ansible/
  â””â”€ roles/
       â”œâ”€ openstack/           # OSA orchestration (site + roles)
       â””â”€ k8s-talos/           # Talos bootstrap and management addons (Flux, CAPI)
```

---

## Prerequisites

- Ubuntu/Debian host with hardware virtualization (KVM) and at least:
  - 128â€¯GiB RAM, 48 vCPUs, >2â€¯TB fast storage (default QCOW images are large)
  - Internet access for Ubuntu cloud images, OpenStack packages, Talos artifacts
- Ability to run commands with sudo/root privileges

Run the host preparation script once:

```bash
sudo ./scripts/init.sh
```

It updates apt, installs libvirt/qemu/OVMF/dnsmasq and supporting tooling (`talosctl`, `kubectl`, `helm`, Terraform, Ansible, jq), and configures `/etc/libvirt/qemu.conf` plus system services.

---

## Workflow

> **Order matters:** bootstrap OpenStack first so Talos has an infrastructure target to manage. Once OpenStack is healthy, bootstrap the Talos management cluster.

### 1. Provision and configure OpenStack

Use the production bootstrap helper rather than invoking Terraform manually:

```bash
./scripts/bootstrap-openstack.sh \
  --action apply \
  --var-file terraform.tfvars
```

Key flags:
- `--action <plan|apply|destroy>` â€” defaults to `apply`
- `--var-file` â€” alternate tfvars (relative or absolute)
- `--workspace` â€” optional Terraform workspace
- `--parallelism` â€” cap Terraform concurrency
- `--upgrade` â€” run `terraform init -upgrade`

Outputs from the script include:
- `ansible_inventory_file` â€” inventory path for manual OSA reruns
- `ssh_private_key_path` â€” SSH key used for the OpenStack VMs
- `{controller,compute,storage}_nodes` â€” network metadata for each VM

Validation snippet (controller node):

```bash
ssh -i terraform/openstack-libvirt/openstack_private_key.pem ubuntu@<controller_ip>
sudo -i
cd /opt/openstack-ansible
source playbooks/openrc
openstack compute service list
lxc-ls -f
```

### 2. Bootstrap the Talos management cluster

Once OpenStack is online, bring up the Talos management plane:

```bash
./scripts/bootstrap-talos.sh \
  --action apply \
  --var-file terraform.tfvars
```

The script mirrors the OpenStack helper (same flags) and invokes Terraform for `terraform/talos-cluster-bootstrap`. Terraform provisions Talos control-plane and worker VMs, generates the required inventories, and `ansible/roles/k8s-talos`:
- Installs Talos on every VM and bootstraps the control plane
- Joins workers and exposes kubeconfig via `talosctl`
- Installs Flux plus Cluster API configured for the OpenStack cloud so Git reconciliation drives tenant infrastructure

The helper prints summarized outputs for master/worker IPs and the generated Talos inventory (`terraform/talos-cluster-bootstrap/ansible_inventory.yaml`), making it easy to rerun Ansible or `talosctl` commands.

---

## Operations & Customization

- **Scaling OpenStack** â€“ edit `terraform/openstack-libvirt/terraform.tfvars` (`*_count`, CPU/RAM/disk). Terraform hashes the Ansible content and tfvars, so reapplying reconciles changes automatically.
- **Network adjustments** â€“ change `network_cidr` inside Terraform modules and update container/tunnel/storage CIDRs in `ansible/roles/openstack/site.yaml`.
- **OSA release** â€“ set `osa_branch` within the OpenStack role to move between stable series.
- **Cinder backing disk** â€“ override `cinder_lvm_device` if the extra disk differs from `/dev/vdb`.
- **Talos releases / Flux config** â€“ tune variables under `terraform/talos-cluster-bootstrap` or defaults in `ansible/roles/k8s-talos` to select Talos versions, Flux Git sources, and Cluster API settings.
- **Manual reruns** â€“ `ansible-playbook -i terraform/openstack-libvirt/ansible_inventory.yaml ansible/roles/openstack/site.yaml` for OpenStack, or reuse the generated Talos inventory with the k8s role.
- **Cleanup** â€“ run `./scripts/bootstrap-<stack>.sh --action destroy` with the same tfvars/workspace settings to tear down each layer.

Expect roughly 30â€“60 minutes for the initial OpenStack deployment. The Talos bootstrap typically completes within minutes once the VMs are available. Re-running the bootstrap scripts is idempotent: Terraform reconciles infrastructure and the downstream Ansible roles/Flux sources ensure software state converges.

---

## Next Steps

1. Generate kubeconfig from Talos (`talosctl kubeconfig ...`) and verify Flux reconciliation status (`kubectl -n flux-system get kustomizations,sources`).
2. Author Cluster API manifests (`Cluster`, `OpenStackCluster`, `MachineDeployment`, `OpenStackMachineTemplate`) in your Flux source repository so Flux continuously deploys tenant clusters onto OpenStack.
3. Layer additional GitOps workloads or platform services on top of the Talos management cluster; Flux will fan out the changes through Cluster API into the OpenStack-backed infrastructure.

This engine gives you complete, declarative controlâ€”from the libvirt host through the OpenStack substrate to Kubernetes workloads governed by Fluxâ€”ready for production-oriented automation, testing, and iterative delivery.
